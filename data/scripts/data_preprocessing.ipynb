{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: soundfile in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: pandas in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: tqdm in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: pooch>=1.1 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: cffi>=1.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: colorama in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pycparser in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: packaging in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\singaporean_english_asr\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install librosa soundfile pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train split:\n",
      "Preprocessing JSON: ../raw_splits\\train_data.json\n",
      "Processed 80 JSON records\n",
      "Standardizing and padding audio files for train split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 80/80 [00:18<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80 audio files\n",
      "Min duration: 1.95s\n",
      "Max duration: 10.43s\n",
      "Mean duration: 5.25s\n",
      "\n",
      "Processing validation split:\n",
      "Preprocessing JSON: ../raw_splits\\validation_data.json\n",
      "Processed 10 JSON records\n",
      "Standardizing and padding audio files for validation split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 10/10 [00:00<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 audio files\n",
      "Min duration: 2.63s\n",
      "Max duration: 11.42s\n",
      "Mean duration: 6.06s\n",
      "\n",
      "Processing test split:\n",
      "Preprocessing JSON: ../raw_splits\\test_data.json\n",
      "Processed 10 JSON records\n",
      "Standardizing and padding audio files for test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 10/10 [00:00<00:00, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 audio files\n",
      "Min duration: 3.35s\n",
      "Max duration: 9.20s\n",
      "Mean duration: 5.06s\n",
      "\n",
      "Preprocessing complete!\n",
      "Processed data saved to: ../processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "raw_splits_dir = \"../raw_splits\"\n",
    "processed_dir = \"../processed\"  \n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "# Create the processed directory and split subdirectories\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "for split in splits:\n",
    "    split_dir = os.path.join(processed_dir, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# Function to preprocess JSON data and save to the new location\n",
    "def preprocess_json(input_json_path, output_json_path):\n",
    "    # Load JSON data\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Create a copy of the data to modify\n",
    "    processed_data = []\n",
    "    \n",
    "    # Process each item\n",
    "    for item in data:\n",
    "        processed_item = {}\n",
    "        \n",
    "        # Extract original_text from nested json and add as separate field\n",
    "        processed_item['text'] = item['json']['original_text'].lower()\n",
    "        \n",
    "        # Copy the flac path but will update it later\n",
    "        processed_item['flac'] = item['flac']\n",
    "        \n",
    "        # Add any other fields you want to keep\n",
    "        processed_data.append(processed_item)\n",
    "    \n",
    "    # Save the processed JSON\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Function to standardize audio files\n",
    "def standardize_audio(input_audio_path, output_audio_path, target_sr=16000, normalize=True, min_duration_sec=1.0):\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(input_audio_path, sr=None)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != target_sr:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        \n",
    "        # Normalize audio if requested\n",
    "        if normalize:\n",
    "            y = librosa.util.normalize(y)\n",
    "        \n",
    "        # Pad if audio is too short\n",
    "        duration = len(y) / target_sr\n",
    "        if duration < min_duration_sec:\n",
    "            pad_length = int((min_duration_sec - duration) * target_sr)\n",
    "            y = np.pad(y, (0, pad_length), mode='constant')\n",
    "            duration = min_duration_sec\n",
    "        \n",
    "        # Save the standardized audio to the new path\n",
    "        sf.write(output_audio_path, y, target_sr)\n",
    "        \n",
    "        return True, duration  # Return success and duration in seconds\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_audio_path}: {e}\")\n",
    "        return False, 0\n",
    "\n",
    "# Main processing loop\n",
    "for split in splits:\n",
    "    print(f\"\\nProcessing {split} split:\")\n",
    "    \n",
    "    # Setup input and output paths\n",
    "    input_json_path = os.path.join(raw_splits_dir, f\"{split}_data.json\")\n",
    "    output_json_path = os.path.join(processed_dir, f\"{split}_data.json\")\n",
    "    output_csv_path = os.path.join(processed_dir, f\"{split}_data.csv\")\n",
    "    \n",
    "    input_split_dir = os.path.join(raw_splits_dir, split)\n",
    "    output_split_dir = os.path.join(processed_dir, split)\n",
    "    \n",
    "    # Process JSON\n",
    "    if os.path.exists(input_json_path):\n",
    "        print(f\"Preprocessing JSON: {input_json_path}\")\n",
    "        processed_json = preprocess_json(input_json_path, output_json_path)\n",
    "        print(f\"Processed {len(processed_json)} JSON records\")\n",
    "        \n",
    "        # Get list of audio files to process\n",
    "        audio_files = []\n",
    "        for item in processed_json:\n",
    "            if isinstance(item['flac'], str) and os.path.exists(item['flac']):\n",
    "                audio_files.append(item['flac'])\n",
    "        \n",
    "        # Process audio files\n",
    "        print(f\"Standardizing and padding audio files for {split} split\")\n",
    "        durations = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        # Update the JSON with new audio paths\n",
    "        for i, item in enumerate(tqdm(processed_json, desc=\"Processing audio files\")):\n",
    "            input_audio_path = item['flac']\n",
    "            \n",
    "            if isinstance(input_audio_path, str) and os.path.exists(input_audio_path):\n",
    "                # Create the output path\n",
    "                filename = os.path.basename(input_audio_path)\n",
    "                output_audio_path = os.path.join(output_split_dir, filename)\n",
    "                \n",
    "                # Process the audio\n",
    "                success, duration = standardize_audio(\n",
    "                    input_audio_path, \n",
    "                    output_audio_path, \n",
    "                    target_sr=16000, \n",
    "                    normalize=True,\n",
    "                    min_duration_sec=1.0\n",
    "                )\n",
    "                \n",
    "                if success:\n",
    "                    # Update the path in the JSON\n",
    "                    processed_json[i]['flac'] = output_audio_path\n",
    "                    durations.append(duration)\n",
    "                    processed_count += 1\n",
    "        \n",
    "        # Save the updated JSON with corrected paths\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(processed_json, f, indent=2)\n",
    "        \n",
    "        # Create a CSV from the processed JSON\n",
    "        df = pd.DataFrame(processed_json)\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        \n",
    "        # Print statistics\n",
    "        if durations:\n",
    "            print(f\"Processed {processed_count} audio files\")\n",
    "            print(f\"Min duration: {min(durations):.2f}s\")\n",
    "            print(f\"Max duration: {max(durations):.2f}s\")\n",
    "            print(f\"Mean duration: {np.mean(durations):.2f}s\")\n",
    "    else:\n",
    "        print(f\"No JSON file found for {split} split: {input_json_path}\")\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "print(f\"Processed data saved to: {processed_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
